* Kafka 知识点

** 基本概念

kafka 高吞吐量的分布式 订阅/发布 消息系统。

broker： 消息中间件的处理节点，一个kafka 节点对应一个 broker，多个 broker 组成一个 kafka 集群。
topic： 主题，kafka 根据topic 对消息进行归类，发到 kafka 集群的每条消息都需要指定一个 topic
producer： 消息生产者，向broker发送消息的客户端
consumer: 消息的消费者 从broker读取消息的客户端
consumerGroup： 每个consumer属于一个特定的 consumenrGroup 一条消息可以发送到多个不同的
consumerGroup，但是一个 consumerGroup 只能有一个 consumer 能够消费该消息
Partition： 一个 topic 可以分多个 partition 每个 partition 是内部有序的。一个 partition 只能
被consumer group 中的至多一个 consumer 所绑定消费，正常情况下，期望 partition 的数量能够与
consumerGropup 真的数量均等，这样能做到负载均衡。

** kafka 消费端，确保一个 partition 在一个消费者组内只能被一个消费者消费。 这句话怎么理解呢？
1. 在同一个消费额组内，一个partition 只能被一个消费者消费
2. 在同一个消费组内，所有的消费者组合起来必定可以消费 topic 下的所有partition
3.在同一个消费组内，一个消费者可以消费多个partition
4.在不同的消费组内，同一个分区可以被多个消费者消。
5.每个消费者组内一定会完整消费 一个topic下的所有 partition


** 消费者组存在的意义

1.对于多应用场景，就可以使用消费组来隔离不同的业务使用场景，从而达到一个 topic 可以被多个消费组重复消费的目的。
2.消费组，与 partition 消费进度绑定，当有新的消费者加入或者推出时，触发 repartition 这个时候 原来的 partition1
可能更改成被 消费者2 进行消费 ，为了避免重复消费，需要从消费组记录的 partition 消费进度 也就是 offset 位置继续消费
可以达到消费者平滑迁移，提高系统可用性。

** repartition 触发时机

1. 消费组内某消费者宕机，促发 partition 
2.消费组内新增消费者，触发 repartition ，提高消费能力
3.topic 下的 partition 增锁，触发 repartition， partition 数量小于消费者，增加消费者是无用的，只能增加 partition 提升消费数度



** 消费者与 ZK 的关系

zk 不仅保存了消费者 消费partition 的进度，同时也保存了消费组的成员列表，partition 的所有者。消费者
partition 的所有者。 消费者想要消费 partition 需要从zk 中获取该消费者对应的分区信息，以及当前分区对应的消费进度。
即 offset 信息。那么partition 应该由那个消费者进行消费，决定因素有哪些呢？ 从之前的图中不难得出，两部重要因素是，消费组
中存货的消费者进行消费。

zk 保存着 集群的 broker topic partition 等 meta 数据；另外还负责 broker 故障发现， partition leader 选举，负载均衡等。

** 消费端的工作流程

1.kafkaConsumer 消费端，用于启动消费进程来消费信息。
2.consumerconfig 消费端配置管理，用于给消费端配置参数相关，比如执行定 kafka 集群，设置自动提交和自动提交时间间隔等参数，都有其来管理。
3.consumerConnector 消费者连接器，通过消费则连接器可以获得 kafka 消息流 然后对消息流而让客户端开始消费消息。

概括为：消费端使用消费者配置管理器，创建出消费者连接器，通过消费连接器创建队列，从队列中的消息由专门的拉去线程从服务端拉去然后写入。
最后由消费者客户端轮询队列中的消息进行消费。



** 常见特性

对于 producer 来说，可以设置同一个消息不会被多次投递，这依赖于 broker 给每个producer 一个编号，
以及对 message 也有相关的编号，所以会对相同的编号消息进行去重复。
Kafka 同样支持 transaction message， 即 batch message 要么全部写入成功，要么全部写入失败。



** kafka 的三种模式

*** 注册方式： 
1. subscribe 方式： 当主题分区数量变化或者 consumer 数量变化时，会进行 rebalance；注册rebalance
监听器，可以手动管理 offset 不注册监听器， kafka 自动管理
2. assign 方式： 手动将 consumer 与 partition 进行对应， kafka 不会进行 rebalance

*** 关键配置：
enable.auto.commit 是否自动提交自己的 offset值；默认时是 true
auto.commit.interval.ms 自动提交时长间隔；默认值是 5000ms
consumer.commitsync(); offset 提交命令；

默认配置

采用默认配置的情况下，既不能完全保证 at-least-once 也不能完全保证 at-most-once

如： 自动提交之后，数据消费流程失败，这样就会有丢失，不能保证 at-least-once；
数据消费成功，但是自动提交失败，可能会导致重复消费，这样也不能呢保证 at-most-once；
但是将自动提交时长设置的足够小，则可以最大限度的保证 at-most-once；

** kafka 的三种模式

*** At most once 模式 （最多一次）

基本思想是保证每一条消息 commit 成功之后，在进行消费处理；
设置自动提交为 false，接收到消息之后，首先 commit，然后再进行消费

*** at least once 模式 （最少一次）

基本思想是保证每一条消息处理成功之后，在进行commit；
设置自动提交为 false 消息处理成功之后，手动进行commit；
采用这种模式时，最好保证消费操作时的“幂等性”，防止重复消费。

*** exactly once 模式 （正好一次）

核心事项时候将 offset 作为唯一id 与消息同时处理，并保证处理的原子性；设置自动提交为 false；消息处
里成功之后在提交


** partition replica log 和 logSegment 的关系

partition replica log 和 logSegment 之间的关系，。消息是以 partition 维度进行管理的。为了提高系统的可用性。
每个partition 都可以设置相应的 replica 副本数，一般在创建 topic 的时候同时制定了 replica 的个数。partition 和 replica
实际的物理存储形式是通过 log 文件展现是，为了防止消息不断写入，log 文件大小持续增长，所以将log 切割成一个一个的 lgosegment。


**  kafka 是如何保证系统的 高可用，数据的可靠性和数据的一致性的？

高可用：
kafka 本身十一个分布式系统，同时采用了 zookeeper 存储元数据信息，提高了系统的高可用性。
2.kafka 是哟该多副本机制，当状态为 leader 的 partition 对应的 broker 宕机或者网络异常，
kafka 会通过选举机制从对应的 replica 列表中 选举出 replica 当作leader 从而继续对外提供读请求
利用多副本机制在一定程度上提供了系统的容错性，从而提升了系统的高可用。

卡靠性：

从producer 端来看 ，可靠性是指生产的消息能够正常的被存粗到partition 上 且消息不会丢失。 kafka 通过 request。required。ack 和
miniinsync。replicas 两个参数配合保证消息不会丢失。

2.request。require。ack 可以设置成 1，0，-1


** 什么是 kafka 

分布式的消息订阅系统，可以用来处理流式数据的。

** kafka 的好处，可以用卡夫卡来做什么

1. 可以进行消峰处理： 上游数据突发流量，下游可能扛不住，或者下游没有足够的处理能力， kafka 可以在在中间
起到一个缓冲的作用， 下游的服务可以按照自己的节奏慢慢处理。
2. 解耦和扩展： 项目开始的时候不确定具体需求，消息队列可以作为接口，解耦业务流程
3. 冗余：可以采用 一对多的方式，一个生产者发布消息，可以被多个订阅的 topci 的服务消费到，供多个毫无关联
的业务使用
4. 健壮性： 消息队列可以堆积请求，消费端业务即使 宕机，也不影响主要的业务流程
5. 异步通信： 很多时候，用户不想也不需要立即处理消息。消息队列提供了异步处理机制。可以讲消息放入队列，然后
在需要的时候进行处理

*** ISR AR 又代表什么？ ISR 伸缩指什么？

:: 需要花时间理解一下

** kafka 中的 zookeeper 起到什么作用，可以不用 zookeeper 么？

zookeeper 是一个分布式协调组件，早期版本 kafka 用 zk 存储 meta 信息存储， consumer 消费状态，group 管理，以及
offset 的值。  zookeeeper 在 kafka 中来选举 controller 和检测 broker 是否存活。

** kafka 的 follower 如何与 leader 同步数据

kafka 的复制机制 不是完全同步，也不是异步复制， 完全同步的话需要，所有follower 复制完成之后才会进行提交
这样性能会有影响，如果是异步复制， 当leader 写入 log 就 commit 这样的话 leader 挂掉，会丢失数据。 
重点： kafka 使用的是 ISR  follower 可以批量的从 leader 复制数据，而且 leader 充分利用磁盘的 顺序读
和 “零拷贝” 提升复制性能，减少 follower 和 leader 的消息差

** 什么情况下 broker 会从 isr 中踢出去

leader 会维护一个与其基本同步的 replica 列表， 这个列表就是 ISR（in sync replica）每个 pardition 都有
一个 ISR 有 leader 进行维护，如果一个 follwer 比一个 leader 落后太多，能活着超过一定的时间没有进行复制，那么
leader 就会将 其从 ISR 中移除。

** kafka 为什么快

1. cache FilesystemCache PageCache 缓存
2. 顺序写技术，操作系统提供的 预读，和写技术，磁盘的顺序写大多数情况比随机写内存还快
3. 零拷贝技术，减少拷贝次数
4. 批量处理，合并小的请求，以流的方式进行交互，
5. pull 拉的模式 使用拉的模式进行消息消费，消费 与处理端能力相同

** kafka producer 如何优化打入速度

增加线程
提高 batch.size
增加更多的 producer 实例
增加 partition 数量
设置 ack=-1 时 如果延时增大： 可以增大 num.replica.fetchers  follower 同步数据的线程数来调节
跨数据中心传输： 增加 socket 缓冲区设置，以及 os tcp 缓冲区设置

** kafka producer 打数据 ack 为 0 1 -1 时 代表的是啥， 设置-1 的时候什么情况下 leader 会认为一条消息 commit 了

1. 1 （默认） 数据发送到卡夫卡之后，经过 leader 成功接收消息的确认，就算发送成功了。这种情况 如果leader 宕机
则数据会丢失
2. 0 生产者将 数据发送之后就不管了，不等待任何返回。这种情况效率传输最高，但是数据可靠性最低
3. -1 producer 需要等待 ISR 中的所有follower 都确认接收到数据之后才算一次发送完成，可靠性最高。 当 ISR 中
所有的 replica 都想 leader 发送 ACK 时 leader 才 commit 这时producer 才认为一个消息 commit 了

** leader crash 时  ISR 为 空怎么办

unclean.leader.election 配置

true 默认允许同步副本成为 leader 由于不同步副本的消息较为滞后，成为 leader 可能会出现消息不一致的情况
false： 不允许不同步副本 成为 leader 此时如果发生 ISR 列表为空， 会一直等待 leader 恢复，降低可用性


** kafka 的 message 格式是 什么样子的

一个 kafka 的 message 由一个固定长度的 header 和一个 可变长度的 消息题 body 组成

header 部分由一个字节 的 magic 文件格式和 四个字节的 CRC32 用于判断 body 消息体是正常构成
当 magic 为 1 时  在  magic 和 CRC32 之间多一个字节的数据： attributes 保存一些相关属性
是否压缩，压缩格式等； 如果 magic 值为0 那么不存在 attributes 属性

body 是有N个字节构成的一个消息体，包含了具体的 key/value 消息

** kafka 中的 consumer group 是什么概念

同一个 topic 的数据，会广播给不同的 group 同一个 group 中的 worker 只有一个 worker 能拿到这个数据。
换句话说，对于同一个topic ，每个 group 都能拿到同样的数据，但是 进入到 group 之后只能被其中的 一个 
worker 消费， worker 的数量一般不超过 partition 的数量 一个partition 只能被一个 workder 消费

** 消息是否会丢失，和重复消费？

1. 消息发送

kafka 可以通过设置 ack 的类型来判断消息接收是否成功确认；
1. 0---表示不进行确认
2. 1---表示当 leader 接收成功时确认
3.-1---表示Leader 和 follower 都接收成功时确认；

当 acks=0 时 不和 kafka 集群进行消息接收确认，则当网络异常缓冲区满了等情况时可能丢失
当 acks=1 时 同步模式下 leader 确认成功但是挂掉，副本没有同步，数据可能丢失

2. 消息消费
kafka 提供两个 consumer 接口，一个 lowlevelapi 和 High-level-api

1. low-level API : 消费者自己维护 offset 可以实现对 kafka 的完全控制
2. high-level API : 封装了 partition 和 offset 的管理，使用简单

如果使用 high-level api 存在一个问题，就是 当消费者从集群当中把消息取出来，并且提交了新的 offset ，
还没来得及消费，服务就挂掉了，那么下次消费前没消费成功的消息就诡异的消失了；

解决方案：
消息丢失 可以将 acks 设置为 -1 将leader 和 follower 同步之后在在确认发送成功。
消费消息  将消息唯一标识保存到 外部介质，每次消费时判断是否处理过。

** kafka 为什么不支持读写分离

1. 数据一致性问题
2. 延时问题

** kafka 中是怎么体现消息顺序性的

kafka 每个partition中的消息在写入时都是有序的，消费时，每个partition 只能被每个 group 中的一个消费者
消费，整个 topic 不保证有序。如果为了保证topic 整个有序，那么将 partition 调整为 1

** 如何实现延迟队列？
** 事务如何实现
** 哪些地方用到了选举



1.1 Kafka 中的 ISR(InSyncRepli)、 OSR(OutSyncRepli)、 AR(AllRepli)代表什么？

ISR：速率和leader相差低于10s的follower的集合

OSR：速率和leader相差大于10s的follwer

AR：所有分区的follower
1.2 Kafka 中的 HW、 LEO 等分别代表什么？

HW：High Water高水位，根据同一分区中最低的LEO决定（Log End Offset）

LEO：每个分区最大的Offset
1.3 Kafka 中是怎么体现消息顺序性的？

在每个分区内，每条消息都有offset，所以消息在同一分区内有序，无法做到全局有序性
1.4 Kafka 中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？

分区器Partitioner用来对分区进行处理的，即消息发送到哪一个分区的问题。序列化器，这个是对数据进行序列化和反序列化的工具。拦截器，即对于消息发送进行一个提前处理和收尾处理的类Interceptor，处理顺利首先通过拦截器=>序列化器=>分区器
1.5 Kafka 生产者客户端的整体结构是什么样子的？使用了几个线程来处理？分别是什么？

使用两个线程：main和sender 线程，main线程会一次经过拦截器、序列化器、分区器将数据发送到RecoreAccumulator线程共享变量，再由sender线程从共享变量中拉取数据发送到kafka broker

batch.size达到此规模消息才发送，linger.ms未达到规模，等待当前时长就发送数据。
1.6 消费组中的消费者个数如果超过 topic 的分区，那么就会有消费者消费不到数据”这句 话是否正确？

这句话是对的，超过分区个数的消费者不会在接收数据，主要原因是一个分区的消息只能够被一个消费者组中的一个消费者消费。
1.7 消费者提交消费位移时提交的是当前消费到的最新消息的 offset 还是 offset+1？

生产者发送数据的offset是从0开始的，消费者消费的数据的offset是从1开始，故最新消息是offset+1
1.8 有哪些情形会造成重复消费？

先消费后提交offset，如果消费完宕机了，则会造成重复消费
1.9 那些情景会造成消息漏消费？

先提交offset，还没消费就宕机了，则会造成漏消费
1.10 当你使用 kafka-topics.sh 创建（删除）了一个 topic 之后， Kafka 背后会执行什么逻辑？

会在 zookeeper 中的/brokers/topics 节点下创建一个新的 topic 节点，如：/brokers/topics/first 触发 Controller 的监听程序 kafka Controller 负责 topic 的创建工作，并更新 metadata cache
1.11 topic 的分区数可不可以增加？如果可以怎么增加？如果不可以，那又是为什么？

可以增加，修改分区个数--alter可以修改分区个数
1.12 topic 的分区数可不可以减少？如果可以怎么减少？如果不可以，那又是为什么？

不可以减少，减少了分区之后，之前的分区中的数据不好处理
1.13 Kafka 有内部的 topic 吗？如果有是什么？有什么所用？

有，__consumer_offsets主要用来在0.9版本以后保存消费者消费的offset
1.14 Kafka 分区分配的概念？

Kafka分区对于Kafka集群来说，分区可以做到负载均衡，对于消费者来说分区可以提高并发度，提高读取效率
1.15 简述 Kafka 的日志目录结构？

每一个分区对应着一个文件夹，命名为topic-0/topic-1…，每个文件夹内有.index和.log文件。
1.16 如果我指定了一个 offset， Kafka Controller 怎么查找到对应的消息？

offset表示当前消息的编号，首先可以通过二分法定位当前消息属于哪个.index文件中，随后采用seek定位的方法查找到当前offset在.index中的位置，此时可以拿到初始的偏移量。通过初始的偏移量再通过seek定位到.log中的消息即可找到。
1.17 聊一聊 Kafka Controller 的作用？

Kafka集群中有一个broker会被选举为Controller，负责管理集群broker的上下线、所有topic的分区副本分配和leader的选举等工作。Controller的工作管理是依赖于zookeeper的。
1.18 Kafka 中有那些地方需要选举？这些地方的选举策略又有哪些？

在ISR中需要选举出Leader，选择策略为先到先得。在分区中需要选举，需要选举出Leader和follower。
1.19 失效副本是指什么？有那些应对措施？

失效副本为速率比leader相差大于10s的follower，ISR会将这些失效的follower踢出，等速率接近leader的10s内，会重新加入ISR
1.20 Kafka 的哪些设计让它有如此高的性能？

    Kafka天生的分布式架构
    对log文件进行了分segment，并对segment建立了索引
    对于单节点使用了顺序读写，顺序读写是指的文件的顺序追加，减少了磁盘寻址的开销，相比随机写速度提升很多
    使用了零拷贝技术，不需要切换到用户态，在内核态即可完成读写操作，且数据的拷贝次数也更少。
